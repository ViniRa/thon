{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Building Part 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code for building the models  \n",
    "_Author: Jimmy Charit√©_  \n",
    "_Email: jimmy.charite@gmail.com_  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following up with part one & three, I try the bag of words and the macro-level text summary statistics approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "retval=os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clean_data=pd.read_pickle('./clean_data/clean_data.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kept_cols=['helpful', 'num_sents', 'num_words', 'readability', 'neg_senti',\n",
    "       'pos_senti', 'neu_senti', 'comp_senti', 'text_lemma',]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Testing Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_rand_state=0\n",
    "test_size=0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = (clean_data[kept_cols].iloc[:,1:]).as_matrix()\n",
    "y = (clean_data[kept_cols].iloc[:,0]).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, \n",
    "                                              random_state=my_rand_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vt = VarianceThreshold()\n",
    "threshold=[p*(1-p) for p in [0, 0.05, 0.1, 0.15]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "std_scale=StandardScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimension Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tsvd=TruncatedSVD()\n",
    "n_components=[100] #limited to keep the training size managable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfidf=TfidfVectorizer(lowercase=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Feature Separator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ExtractText(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Separates the features by numerical and text\n",
    "    \"\"\"\n",
    "    def __init__(self, text,n_text=-1):\n",
    "        self.text = text\n",
    "        self.n_text=n_text\n",
    "\n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, data_dict):\n",
    "        if(self.text):\n",
    "            return X[:,self.n_text]\n",
    "        else:\n",
    "            return X[:,:self.n_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import FeatureUnion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although tuning is not necessary for Naive Bayes, I pass the default parameters of those models to GridSearchCV anyway so that I can do a direct pair-wise comparison with the other models across the different steps of cross-validation.  \n",
    "\n",
    "In the interest of time, I didn't use the SVM classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb_clf=GaussianNB()\n",
    "priors=[None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "qda_clf=QuadraticDiscriminantAnalysis()\n",
    "reg_param=[0.0, 0.25, 0.5, 0.75]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "log_clf=LogisticRegression(penalty='l2')\n",
    "C=[0.001 , 0.01, 10, 100,1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf_clf=RandomForestClassifier()\n",
    "n_estimators=[100,200]\n",
    "max_features=[.1,.3,.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dtree=DecisionTreeClassifier(max_depth=None, min_samples_split=2)\n",
    "bagTree_clf=BaggingClassifier(base_estimator=dtree)\n",
    "max_samples=[.3,.6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class_weight=['balanced']\n",
    "class_weight.extend([{1: w} for w in [1, 2, 10]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from imblearn import pipeline #needed if mixing imblearn with sklearn classes\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I plan on using imblearn classes for later iterations so I use it's pipeline in the beginning for convenience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_jobs=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_folds=10\n",
    "skfold = StratifiedKFold(n_splits=n_folds,random_state=my_rand_state, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Main Feature Union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_union=FeatureUnion(transformer_list=[('text_pipe',pipeline.Pipeline([('extract',ExtractText(text=True)),\n",
    "                                                                       ('tfidf',tfidf),\n",
    "                                                                       ('tsvd',tsvd)])),\n",
    "                                        ('numb_pipe',pipeline.Pipeline([('extract',ExtractText(text=False)),\n",
    "                                                                       ('vt',vt),\n",
    "                                                                       ('scale',std_scale)]))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Bayes Estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb_clf_b = pipeline.Pipeline(steps=[('union',ft_union),('clf',nb_clf)])\n",
    "nb_clf_est_b = GridSearchCV(estimator=nb_clf_b,cv=skfold,\n",
    "              scoring='roc_auc',n_jobs=n_jobs,\n",
    "              param_grid=dict(union__text_pipe__tsvd__n_components=n_components,\n",
    "                              union__numb_pipe__vt__threshold=threshold,\n",
    "                              clf__priors=priors))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### QDA Estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "qda_clf_b = pipeline.Pipeline(steps=[('union',ft_union),('clf',qda_clf)])\n",
    "qda_clf_est_b = GridSearchCV(estimator=qda_clf_b,cv=skfold,\n",
    "              scoring='roc_auc',n_jobs=n_jobs,\n",
    "              param_grid=dict(union__text_pipe__tsvd__n_components=n_components,\n",
    "                              union__numb_pipe__vt__threshold=threshold,\n",
    "                              clf__reg_param=reg_param))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "log_clf_b = pipeline.Pipeline(steps=[('union',ft_union),('clf',log_clf)])\n",
    "log_clf_est_b = GridSearchCV(estimator=log_clf_b,cv=skfold,\n",
    "              scoring='roc_auc',n_jobs=n_jobs,\n",
    "              param_grid=dict(union__text_pipe__tsvd__n_components=n_components,\n",
    "                              union__numb_pipe__vt__threshold=threshold,\n",
    "                              clf__C=C,\n",
    "                              clf__class_weight=class_weight))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest Estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf_clf_b = pipeline.Pipeline(steps=[('union',ft_union),('clf',rf_clf)])\n",
    "rf_clf_est_b = GridSearchCV(estimator=rf_clf_b,cv=skfold,\n",
    "              scoring='roc_auc',n_jobs=n_jobs,\n",
    "              param_grid=dict(union__text_pipe__tsvd__n_components=n_components,\n",
    "                              union__numb_pipe__vt__threshold=threshold,\n",
    "                              clf__n_estimators=n_estimators,\n",
    "                              clf__max_features=max_features,\n",
    "                              clf__class_weight=class_weight))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting Estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic Estimators: no bag of words or PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_ft = ft_union.fit_transform(X=X,y=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X), len(y) , len(X_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_clf_est_b.fit(X_train,y_train)\n",
    "joblib.dump(nb_clf_est_b, './other_output/merged/nb_clf_est_b.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "qda_clf_est_b.fit(X_train,y_train)\n",
    "joblib.dump(qda_clf_est_b, './other_output/merged/qda_clf_est_b.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "log_clf_est_b.fit(X_train,y_train)\n",
    "joblib.dump(log_clf_est_b, './other_output/merged/log_clf_est_b.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf_clf_est_b.fit(X_train,y_train)\n",
    "joblib.dump(rf_clf_est_b, './other_output/merged/rf_clf_est_b.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb_clf_est_b=joblib.load('./other_output/merged/nb_clf_est_b.pkl')\n",
    "qda_clf_est_b=joblib.load('./other_output/merged/qda_clf_est_b.pkl')\n",
    "log_clf_est_b=joblib.load('./other_output/merged/log_clf_est_b.pkl')\n",
    "rf_clf_est_b=joblib.load('./other_output/merged/rf_clf_est_b.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic Estimators: no bag of words or PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb_fpr, nb_tpr, _ = roc_curve(y_test, \n",
    "                    nb_clf_est_b.predict_proba(X_test)[:,1])\n",
    "nb_roc_auc = auc(nb_fpr, nb_tpr)\n",
    "\n",
    "qda_fpr, qda_tpr, _ = roc_curve(y_test, \n",
    "                    qda_clf_est_b.predict_proba(X_test)[:,1])\n",
    "qda_roc_auc = auc(qda_fpr, qda_tpr)\n",
    "\n",
    "log_fpr, log_tpr, _ = roc_curve(y_test, \n",
    "                    log_clf_est_b.predict_proba(X_test)[:,1])\n",
    "log_roc_auc = auc(log_fpr, log_tpr)\n",
    "\n",
    "rf_fpr, rf_tpr, _ = roc_curve(y_test, \n",
    "                    rf_clf_est_b.predict_proba(X_test)[:,1])\n",
    "rf_roc_auc = auc(rf_fpr, rf_tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(nb_fpr, nb_tpr, color='cyan', linestyle='--',\n",
    "         label='NB (area = %0.2f)' % nb_roc_auc, lw=2)\n",
    "\n",
    "plt.plot(qda_fpr, qda_tpr, color='indigo', linestyle='--',\n",
    "         label='QDA (area = %0.2f)' % qda_roc_auc, lw=2)\n",
    "\n",
    "plt.plot(log_fpr, log_tpr, color='seagreen', linestyle='--',\n",
    "         label='LOG (area = %0.2f)' % log_roc_auc, lw=2)\n",
    "\n",
    "plt.plot(rf_fpr, rf_tpr, color='blue', linestyle='--',\n",
    "         label='RF (area = %0.2f)' % rf_roc_auc, lw=2)\n",
    "\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', lw=2, color='k',\n",
    "         label='Luck')\n",
    "\n",
    "plt.xlim([-0.05, 1.05])\n",
    "plt.ylim([-0.05, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curves of Basic Models Using BOW & Macro-Text Stats')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig('./plots/ROC_Basic_BOW_MERGED.png', bbox_inches='tight')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py35]",
   "language": "python",
   "name": "conda-env-py35-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
