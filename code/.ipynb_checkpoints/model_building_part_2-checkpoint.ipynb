{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Building Part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code for building the models\n",
    "_Author: Jimmy Charité_  \n",
    "_Email: jimmy.charite@gmail.com_  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following up with model building part one, I experiment with using the word vectors and class imbalance corrections like over sampling with SMOTE and under sampling Tomek link removal.\n",
    "\n",
    "I limit myself to the random forest, the best performing model in part 2, you streamline the exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "retval=os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clean_data=pd.read_pickle('./clean_data/clean_data.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>helpful</th>\n",
       "      <th>num_sents</th>\n",
       "      <th>num_words</th>\n",
       "      <th>readability</th>\n",
       "      <th>neg_senti</th>\n",
       "      <th>pos_senti</th>\n",
       "      <th>neu_senti</th>\n",
       "      <th>comp_senti</th>\n",
       "      <th>text_lemma</th>\n",
       "      <th>vec0</th>\n",
       "      <th>...</th>\n",
       "      <th>vec290</th>\n",
       "      <th>vec291</th>\n",
       "      <th>vec292</th>\n",
       "      <th>vec293</th>\n",
       "      <th>vec294</th>\n",
       "      <th>vec295</th>\n",
       "      <th>vec296</th>\n",
       "      <th>vec297</th>\n",
       "      <th>vec298</th>\n",
       "      <th>vec299</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>3.610918</td>\n",
       "      <td>6.742881</td>\n",
       "      <td>0.079</td>\n",
       "      <td>0.068</td>\n",
       "      <td>0.853</td>\n",
       "      <td>-0.1027</td>\n",
       "      <td>product arrive label peanut actually small siz...</td>\n",
       "      <td>0.033346</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.023125</td>\n",
       "      <td>-0.005069</td>\n",
       "      <td>0.007344</td>\n",
       "      <td>-0.045929</td>\n",
       "      <td>-0.017832</td>\n",
       "      <td>-0.018206</td>\n",
       "      <td>-0.017281</td>\n",
       "      <td>0.012410</td>\n",
       "      <td>0.020198</td>\n",
       "      <td>-0.002511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>3.555348</td>\n",
       "      <td>6.734948</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.448</td>\n",
       "      <td>0.552</td>\n",
       "      <td>0.9468</td>\n",
       "      <td>great taffy great price wide assortment yummy ...</td>\n",
       "      <td>0.037825</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.015524</td>\n",
       "      <td>0.009058</td>\n",
       "      <td>0.020853</td>\n",
       "      <td>-0.058746</td>\n",
       "      <td>-0.001076</td>\n",
       "      <td>-0.013715</td>\n",
       "      <td>-0.035464</td>\n",
       "      <td>0.006317</td>\n",
       "      <td>0.023066</td>\n",
       "      <td>0.012566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>4.499810</td>\n",
       "      <td>6.743588</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.163</td>\n",
       "      <td>0.809</td>\n",
       "      <td>0.8830</td>\n",
       "      <td>get wild hair taffy order pound bag taffy enjo...</td>\n",
       "      <td>0.039023</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.011637</td>\n",
       "      <td>0.008717</td>\n",
       "      <td>0.007918</td>\n",
       "      <td>-0.046595</td>\n",
       "      <td>-0.012542</td>\n",
       "      <td>-0.028316</td>\n",
       "      <td>-0.036677</td>\n",
       "      <td>0.015261</td>\n",
       "      <td>0.016227</td>\n",
       "      <td>0.008930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>4.143135</td>\n",
       "      <td>6.742527</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.273</td>\n",
       "      <td>0.693</td>\n",
       "      <td>0.9346</td>\n",
       "      <td>saltwater taffy great flavor soft chewy candy ...</td>\n",
       "      <td>0.038912</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.010440</td>\n",
       "      <td>0.006156</td>\n",
       "      <td>0.007695</td>\n",
       "      <td>-0.039642</td>\n",
       "      <td>-0.012080</td>\n",
       "      <td>-0.026868</td>\n",
       "      <td>-0.018743</td>\n",
       "      <td>0.009134</td>\n",
       "      <td>0.021543</td>\n",
       "      <td>0.016047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>3.526361</td>\n",
       "      <td>6.737915</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.480</td>\n",
       "      <td>0.520</td>\n",
       "      <td>0.9487</td>\n",
       "      <td>taffy good soft chewy flavor amazing definitel...</td>\n",
       "      <td>0.043776</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.010004</td>\n",
       "      <td>-0.003239</td>\n",
       "      <td>0.014308</td>\n",
       "      <td>-0.050601</td>\n",
       "      <td>-0.024100</td>\n",
       "      <td>-0.023046</td>\n",
       "      <td>-0.017151</td>\n",
       "      <td>0.017009</td>\n",
       "      <td>0.010729</td>\n",
       "      <td>0.004194</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 309 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   helpful  num_sents  num_words  readability  neg_senti  pos_senti  \\\n",
       "0      0.0   0.693147   3.610918     6.742881      0.079      0.068   \n",
       "1      0.0   1.386294   3.555348     6.734948      0.000      0.448   \n",
       "2      0.0   1.609438   4.499810     6.743588      0.029      0.163   \n",
       "3      0.0   1.609438   4.143135     6.742527      0.034      0.273   \n",
       "4      0.0   1.609438   3.526361     6.737915      0.000      0.480   \n",
       "\n",
       "   neu_senti  comp_senti                                         text_lemma  \\\n",
       "0      0.853     -0.1027  product arrive label peanut actually small siz...   \n",
       "1      0.552      0.9468  great taffy great price wide assortment yummy ...   \n",
       "2      0.809      0.8830  get wild hair taffy order pound bag taffy enjo...   \n",
       "3      0.693      0.9346  saltwater taffy great flavor soft chewy candy ...   \n",
       "4      0.520      0.9487  taffy good soft chewy flavor amazing definitel...   \n",
       "\n",
       "       vec0    ...       vec290    vec291    vec292    vec293    vec294  \\\n",
       "0  0.033346    ...    -0.023125 -0.005069  0.007344 -0.045929 -0.017832   \n",
       "1  0.037825    ...    -0.015524  0.009058  0.020853 -0.058746 -0.001076   \n",
       "2  0.039023    ...    -0.011637  0.008717  0.007918 -0.046595 -0.012542   \n",
       "3  0.038912    ...    -0.010440  0.006156  0.007695 -0.039642 -0.012080   \n",
       "4  0.043776    ...    -0.010004 -0.003239  0.014308 -0.050601 -0.024100   \n",
       "\n",
       "     vec295    vec296    vec297    vec298    vec299  \n",
       "0 -0.018206 -0.017281  0.012410  0.020198 -0.002511  \n",
       "1 -0.013715 -0.035464  0.006317  0.023066  0.012566  \n",
       "2 -0.028316 -0.036677  0.015261  0.016227  0.008930  \n",
       "3 -0.026868 -0.018743  0.009134  0.021543  0.016047  \n",
       "4 -0.023046 -0.017151  0.017009  0.010729  0.004194  \n",
       "\n",
       "[5 rows x 309 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del clean_data['text_lemma']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['helpful', 'num_sents', 'num_words', 'readability', 'neg_senti',\n",
       "       'pos_senti', 'neu_senti', 'comp_senti', 'vec0', 'vec1',\n",
       "       ...\n",
       "       'vec290', 'vec291', 'vec292', 'vec293', 'vec294', 'vec295', 'vec296',\n",
       "       'vec297', 'vec298', 'vec299'],\n",
       "      dtype='object', length=308)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Testing Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_rand_state=0\n",
    "test_size=0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = (clean_data.iloc[:,1:]).as_matrix()\n",
    "y = (clean_data.iloc[:,0]).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, \n",
    "                                              random_state=my_rand_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vt = VarianceThreshold()\n",
    "threshold=[p*(1-p) for p in [0, 0.05, 0.1, 0.15]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note, since the formula for the variance of binary variables is p*(1-p), where p is the proportion of times that the binary variable is 1, I use the proportion to define the variance thresholds. The max variance is 0.25 at p=0.5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "std_scale=StandardScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class Imbalance Corrections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jim/anaconda2/envs/py35/lib/python3.5/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import TomekLinks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "smote = SMOTE(random_state=my_rand_state)\n",
    "tl = TomekLinks(random_state=my_rand_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf_clf=RandomForestClassifier()\n",
    "n_estimators=[100,200]\n",
    "max_features=[.1,.3,.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class_weight=['balanced']\n",
    "class_weight.extend([{1: w} for w in [1, 2, 10]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from imblearn import pipeline #needed if mixing imblearn with sklearn classes\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I plan on using imblearn classes for later iterations so I use it's pipeline in the beginning for convenience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_jobs=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_folds=10\n",
    "skfold = StratifiedKFold(n_splits=n_folds,random_state=my_rand_state, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest Estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf_clf_b = pipeline.Pipeline(steps=[('vt',vt),('scale',std_scale),('clf',rf_clf)])\n",
    "rf_clf_est_b_wv = GridSearchCV(estimator=rf_clf_b,cv=skfold,\n",
    "              scoring='roc_auc',n_jobs=n_jobs,\n",
    "              param_grid=dict(vt__threshold=threshold,\n",
    "              clf__n_estimators=n_estimators,\n",
    "              clf__max_features=max_features,\n",
    "              clf__class_weight=class_weight))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_clf_b_smote = pipeline.Pipeline(steps=[('vt',vt),('smote',smote),('scale',std_scale),('clf',rf_clf)])\n",
    "rf_clf_est_b_wv_smote = GridSearchCV(estimator=rf_clf_b_smote,cv=skfold,\n",
    "              scoring='roc_auc',n_jobs=n_jobs,\n",
    "              param_grid=dict(vt__threshold=threshold,\n",
    "              clf__n_estimators=n_estimators,\n",
    "              clf__max_features=max_features,\n",
    "              clf__class_weight=class_weight))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf_clf_b_tl = pipeline.Pipeline(steps=[('vt',vt),('tl',tl),('scale',std_scale),('clf',rf_clf)])\n",
    "rf_clf_est_b_wv_tl = GridSearchCV(estimator=rf_clf_b_tl,cv=skfold,\n",
    "              scoring='roc_auc',n_jobs=n_jobs,\n",
    "              param_grid=dict(vt__threshold=threshold,\n",
    "              clf__n_estimators=n_estimators,\n",
    "              clf__max_features=max_features,\n",
    "              clf__class_weight=class_weight))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting Estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic Estimators: no bag of words or PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_clf_est_b_wv.fit(X_train,y_train)\n",
    "joblib.dump(rf_clf_est_b_wv, './other_output/rf_clf_est_b_wv.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_clf_est_b_wv_smote.fit(X_train,y_train)\n",
    "joblib.dump(rf_clf_est_b_wv_smote, './other_output/rf_clf_est_b_wv_smote.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_clf_est_b_wv_tl.fit(X_train,y_train)\n",
    "joblib.dump(rf_clf_est_b_wv_tl, './other_output/rf_clf_est_b_wv_tl.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf_clf_est_b_wv=joblib.load('./other_output/rf_clf_est_b_wv.pkl')\n",
    "rf_clf_est_b_wv_smote=joblib.load('./other_output/rf_clf_est_b_wv_smote.pkl')\n",
    "rf_clf_est_b_wv_tl=joblib.load('./other_output/rf_clf_est_b_wv_tl.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic Estimators: no bag of words or PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf_fpr, rf_tpr, _ = roc_curve(y_test, \n",
    "                    rf_clf_est_b_wv.predict_proba(X_test)[:,1])\n",
    "rf_roc_auc = auc(rf_fpr, rf_tpr)\n",
    "\n",
    "rf_fpr_smote, rf_tpr_smote, _ = roc_curve(y_test, \n",
    "                    rf_clf_est_b_wv_smote.predict_proba(X_test)[:,1])\n",
    "rf_roc_auc_smote = auc(rf_fpr_smote, rf_tpr_smote)\n",
    "\n",
    "rf_fpr_tl, rf_tpr_tl, _ = roc_curve(y_test, \n",
    "                    rf_clf_est_b_wv_tl.predict_proba(X_test)[:,1])\n",
    "rf_roc_auc_tl = auc(rf_fpr_tl, rf_tpr_tl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(rf_fpr, rf_tpr, color='cyan', linestyle='--',\n",
    "         label='RF (area = %0.2f)' % rf_roc_auc, lw=2)\n",
    "\n",
    "plt.plot(rf_fpr_smote, rf_tpr_smote, color='indigo', linestyle='--',\n",
    "         label='RF w/ SMOTE (area = %0.2f)' % rf_roc_auc_smote, lw=2)\n",
    "\n",
    "plt.plot(rf_fpr_tl, rf_tpr_tl, color='seagreen', linestyle='--',\n",
    "         label='RF w/ Tomek Links (area = %0.2f)' % rf_roc_auc_tl, lw=2)\n",
    "\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', lw=2, color='k',\n",
    "         label='Luck')\n",
    "\n",
    "plt.xlim([-0.05, 1.05])\n",
    "plt.ylim([-0.05, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curves of Basic Models')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig('./plots/ROC_Part_2.png', bbox_inches='tight')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py35]",
   "language": "python",
   "name": "conda-env-py35-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
